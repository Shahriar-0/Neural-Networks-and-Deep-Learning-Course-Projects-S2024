{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    Flatten,\n",
    "    Reshape,\n",
    "    Conv2DTranspose,\n",
    "    LeakyReLU,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Rescaling,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import sonnet as snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 32, 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63565 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "anime_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/anime_face/images\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_train_ds, anime_val_ds = anime_train_ds.take(50000), anime_train_ds.skip(50000)\n",
    "anime_val_ds, anime_test_ds = anime_val_ds.take(10000), anime_val_ds.skip(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_and_normalise_images(data):\n",
    "    images = data\n",
    "    data = (tf.cast(images, tf.float32) / 255.0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack(h, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "\n",
    "    for i in range(num_residual_layers):\n",
    "        h_i = tf.nn.relu(h)\n",
    "\n",
    "        h_i = Conv2D(\n",
    "            output_channels=num_residual_hiddens,\n",
    "            kernel_shape=(3, 3),\n",
    "            name=\"res3x3_%d\" % i,\n",
    "        )(h_i)\n",
    "        h_i = tf.nn.relu(h_i)\n",
    "\n",
    "        h_i = Conv2D(\n",
    "            output_channels=num_hiddens,\n",
    "            kernel_shape=(1, 1),\n",
    "            name=\"res1x1_%d\" % i,\n",
    "        )(h_i)\n",
    "\n",
    "        h += h_i\n",
    "\n",
    "    return tf.nn.relu(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(\n",
    "        self, num_hiddens, num_residual_layers, num_residual_hiddens, name=\"encoder\"\n",
    "    ):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        self._num_hiddens = num_hiddens\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._num_residual_hiddens = num_residual_hiddens\n",
    "\n",
    "    def _build(self, x):\n",
    "        \n",
    "        h = Conv2D(\n",
    "            output_channels=self._num_hiddens / 2,\n",
    "            kernel_shape=(4, 4),\n",
    "            stride=(2, 2),\n",
    "        )(x)\n",
    "        h = relu(h)\n",
    "\n",
    "        h = Conv2D(\n",
    "            output_channels=self._num_hiddens,\n",
    "            kernel_shape=(4, 4),\n",
    "            stride=(2, 2),\n",
    "        )(h)\n",
    "        h = relu(h)\n",
    "\n",
    "        h = Conv2D(\n",
    "            output_channels=self._num_hiddens,\n",
    "            kernel_shape=(3, 3),\n",
    "            stride=(1, 1),\n",
    "        )(h)\n",
    "\n",
    "        h = residual_stack(\n",
    "            h, self._num_hiddens, self._num_residual_layers, self._num_residual_hiddens\n",
    "        )\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(\n",
    "        self, num_hiddens, num_residual_layers, num_residual_hiddens, name=\"decoder\"\n",
    "    ):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self._num_hiddens = num_hiddens\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._num_residual_hiddens = num_residual_hiddens\n",
    "\n",
    "    def _build(self, x):\n",
    "        \n",
    "        h = Conv2D(\n",
    "            output_channels=self._num_hiddens,\n",
    "            kernel_shape=(3, 3),\n",
    "        )(x)\n",
    "\n",
    "        h = residual_stack(\n",
    "            h, self._num_hiddens, self._num_residual_layers, self._num_residual_hiddens\n",
    "        )\n",
    "\n",
    "        h = Conv2DTranspose(\n",
    "            output_channels=int(self._num_hiddens / 2),\n",
    "            output_shape=None,\n",
    "            kernel_shape=(4, 4),\n",
    "            stride=(2, 2),\n",
    "        )(h)\n",
    "        h = relu(h)\n",
    "\n",
    "        x_recon = Conv2DTranspose(\n",
    "            output_channels=3,\n",
    "            output_shape=None,\n",
    "            kernel_shape=(3, 3),\n",
    "        )(h)\n",
    "\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_updates = 15000\n",
    "num_hiddens = 32\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "embedding_dim = 32\n",
    "num_embeddings = 128\n",
    "commitment_cost = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iterator = (\n",
    "    tf.data.Dataset.from_tensor_slices(anime_train_ds)\n",
    "    .map(cast_and_normalise_images)\n",
    "    .shuffle(10000)\n",
    "    .repeat(-1)\n",
    "    .batch(batch_size)).make_one_shot_iterator()\n",
    "\n",
    "train_dataset_batch = train_dataset_iterator.get_next()\n",
    "\n",
    "\n",
    "valid_dataset_iterator = (\n",
    "    tf.data.Dataset.from_tensor_slices(anime_val_ds)\n",
    "    .map(cast_and_normalise_images)\n",
    "    .repeat(1)\n",
    "    .batch(batch_size)).make_initializable_iterator()\n",
    "\n",
    "valid_dataset_batch = valid_dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
    "decoder = Decoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
    "pre_vq_conv1 = Conv2D(output_channels=embedding_dim, kernel_shape=(1, 1), stride=(1, 1), name=\"to_vq\")\n",
    "vq_vae = snt.nets.VectorQuantizer(\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_embeddings=num_embeddings,\n",
    "    commitment_cost=commitment_cost,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "z = pre_vq_conv1(encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_output_train = vq_vae(z, is_training=True)\n",
    "x_recon = decoder(vq_output_train[\"quantize\"])\n",
    "recon_error = tf.reduce_mean((x_recon - x) ** 2)\n",
    "loss = recon_error + vq_output_train[\"loss\"]\n",
    "\n",
    "vq_output_eval = vq_vae(z, is_training=False)\n",
    "x_recon_eval = decoder(vq_output_eval[\"quantize\"])\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "train_op = optimizer.minimize(loss)\n",
    "sess = tf.train.SingularMonitoredSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_recon_error = []\n",
    "\n",
    "for i in tqdm(range(num_training_updates)):\n",
    "    feed_dict = {x: sess.run(train_dataset_batch)}\n",
    "    results = sess.run([train_op, recon_error], feed_dict)\n",
    "    train_res_recon_error.append(results[1])\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"%d iterations\" % i)\n",
    "        print(\"recon_error: %.3f\" % np.mean(train_res_recon_error[-100:]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_res_recon_error)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
